{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "import collections\n",
    "from pprint import pprint\n",
    "import json\n",
    "import re\n",
    "\n",
    "space = re.compile(r'\\s')\n",
    "period = re.compile(r'(?<![A-Z])\\.|(?<!\\w)\\'(?!\\w)')\n",
    "punct = re.compile(r'[^\\'#@\\.\\w]')\n",
    "\n",
    "def tokenize(sent):\n",
    "    sent = space.split(sent)\n",
    "    to = []\n",
    "    tokens = []\n",
    "    for t in sent:\n",
    "        if t:\n",
    "            to += period.split(t)\n",
    "    for t in to:\n",
    "        if t:\n",
    "            tokens += punct.split(t)\n",
    "    return [a for a in tokens if a is not '']\n",
    "\n",
    "def get_lyrics_years(songs):\n",
    "    lyrics = []\n",
    "    years = []\n",
    "    \n",
    "    for song_id in list(songs.keys()):\n",
    "        yr = songs[song_id][\"year\"]\n",
    "        if not yr or yr < 1940:\n",
    "            continue\n",
    "        lyrics.append(songs[song_id][\"lyrics\"].lower() + \"\\n{}\\n{}\".format(\n",
    "                songs[song_id][\"artist\"], songs[song_id][\"title\"]))\n",
    "        years.append(yr)\n",
    "        \n",
    "    return np.array(lyrics), np.array(years)\n",
    "\n",
    "def doc_vec(doc):\n",
    "    doc = [word for word in doc if word in w2v.wv.vocab]\n",
    "    return np.mean(w2v[doc], axis=0)\n",
    "\n",
    "def load_and_tokenize_data(path):\n",
    "    songs_file = open(path, \"r+\")\n",
    "    songs_dict = json.load(songs_file)\n",
    "\n",
    "    lyrics, years = get_lyrics_years(songs_dict)\n",
    "    tokenized_lyrics = []\n",
    "\n",
    "    print(\"[Tokenizing lyrics]\")\n",
    "    for l in lyrics:\n",
    "        tokenized_lyrics.append(tokenize(l))\n",
    "    print(\"[Done]\")\n",
    "    \n",
    "    return tokenized_lyrics, years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_model(songs, years):\n",
    "    x_train, x_dev, y_train, y_dev = train_test_split(songs, years, \n",
    "                                                      test_size=0.30, \n",
    "                                                      random_state=42)\n",
    "    maxAcc = 0\n",
    "    penaltyC = [10 ** i for i in range(-2, 2)]\n",
    "    best_model = None\n",
    "    for c in penaltyC:\n",
    "        model = LogisticRegression(C=c, penalty=\"l2\",\n",
    "                                   solver='liblinear', \n",
    "                                   random_state=42,\n",
    "                                   multi_class=\"auto\")\n",
    "        model.fit(x_train, y_train)\n",
    "        acc = 100 * metrics.accuracy_score(y_dev, model.predict(x_dev))\n",
    "        print(acc, maxAcc)\n",
    "        if acc > maxAcc:\n",
    "            best_model = model\n",
    "            maxAcc = acc\n",
    "                \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "def test_and_print(x_test, y_test, model, lb, rng=5):\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = lb.inverse_transform(y_pred)\n",
    "    \n",
    "    print(\"\\nModel Accuracy: %.3f\" % metrics.accuracy_score(y_test, y_pred))\n",
    "    #most Frequent Tag: \n",
    "    \n",
    "    mfTags = [Counter(y_test).most_common(1)[0][0]]*len(y_test) \n",
    "    print(\"MostFreqTag Accuracy: %.3f\" % metrics.accuracy_score(y_test, mfTags))\n",
    "    \n",
    "    prec, recall, fscore, support = metrics.precision_recall_fscore_support(y_test, y_pred, \n",
    "                                                                            labels=lb.classes_)\n",
    "    print([\"Tag\", \"Prec\", \"Recall\", \"F1\"])\n",
    "    for i,c in enumerate(lb.classes_):\n",
    "        print([c, \"%.3f\" % prec[i], \"%.3f\" % recall[i], \"%.3f\" % fscore[i]])\n",
    "        \n",
    "    y_pred = [(y // rng) * rng for y in y_pred]\n",
    "    y_test = [(y // rng) * rng for y in y_test]\n",
    "    \n",
    "    classes = set([(y // rng) * rng for y in lb.classes_])\n",
    "    \n",
    "    rng_encoder = LabelEncoder()\n",
    "    rng_encoder.fit_transform(list(classes))\n",
    "    \n",
    "    prec, recall, fscore, support = metrics.precision_recall_fscore_support(y_test, y_pred, \n",
    "                                                                            labels=rng_encoder.classes_)\n",
    "    \n",
    "    print(\"Accuracies for ranges of length\", rng)\n",
    "    print([\"Tag\", \"Prec\", \"Recall\", \"F1\"])\n",
    "    for i,c in enumerate(rng_encoder.classes_):\n",
    "        print(str(c) + \"-\" + str(c + rng),\n",
    "               \"%.3f\" % prec[i], \"%.3f\" % recall[i], \"%.3f\" % fscore[i])\n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 0.171\n",
      "MostFreqTag Accuracy: 0.120\n",
      "['Tag', 'Prec', 'Recall', 'F1']\n",
      "[1979, '0.000', '0.000', '0.000']\n",
      "[1980, '0.000', '0.000', '0.000']\n",
      "[1981, '0.000', '0.000', '0.000']\n",
      "[1982, '0.000', '0.000', '0.000']\n",
      "[1983, '0.000', '0.000', '0.000']\n",
      "[1984, '0.000', '0.000', '0.000']\n",
      "[1985, '0.000', '0.000', '0.000']\n",
      "[1986, '0.000', '0.000', '0.000']\n",
      "[1987, '0.000', '0.000', '0.000']\n",
      "[1988, '0.000', '0.000', '0.000']\n",
      "[1989, '0.000', '0.000', '0.000']\n",
      "[1990, '0.000', '0.000', '0.000']\n",
      "[1991, '0.000', '0.000', '0.000']\n",
      "[1992, '0.000', '0.000', '0.000']\n",
      "[1993, '0.000', '0.000', '0.000']\n",
      "[1994, '0.389', '0.222', '0.283']\n",
      "[1995, '0.000', '0.000', '0.000']\n",
      "[1996, '0.000', '0.000', '0.000']\n",
      "[1997, '0.500', '0.023', '0.044']\n",
      "[1998, '0.000', '0.000', '0.000']\n",
      "[1999, '0.000', '0.000', '0.000']\n",
      "[2000, '0.179', '0.060', '0.090']\n",
      "[2001, '0.189', '0.086', '0.119']\n",
      "[2002, '0.000', '0.000', '0.000']\n",
      "[2003, '0.100', '0.051', '0.067']\n",
      "[2004, '0.000', '0.000', '0.000']\n",
      "[2005, '0.125', '0.041', '0.062']\n",
      "[2006, '0.060', '0.028', '0.038']\n",
      "[2007, '0.174', '0.035', '0.058']\n",
      "[2008, '0.047', '0.018', '0.026']\n",
      "[2009, '0.125', '0.013', '0.023']\n",
      "[2010, '0.108', '0.025', '0.041']\n",
      "[2011, '0.069', '0.018', '0.028']\n",
      "[2012, '0.073', '0.094', '0.082']\n",
      "[2013, '0.124', '0.143', '0.133']\n",
      "[2014, '0.119', '0.127', '0.123']\n",
      "[2015, '0.122', '0.165', '0.141']\n",
      "[2016, '0.161', '0.299', '0.209']\n",
      "[2017, '0.185', '0.243', '0.210']\n",
      "[2018, '0.292', '0.506', '0.370']\n",
      "[2019, '0.077', '0.006', '0.011']\n",
      "Accuracies for ranges of length 5\n",
      "['Tag', 'Prec', 'Recall', 'F1']\n",
      "1975-1980 0.000 0.000 0.000\n",
      "1980-1985 0.000 0.000 0.000\n",
      "1985-1990 0.000 0.000 0.000\n",
      "1990-1995 0.614 0.142 0.231\n",
      "1995-2000 0.292 0.027 0.050\n",
      "2000-2005 0.314 0.093 0.143\n",
      "2005-2010 0.281 0.081 0.126\n",
      "2010-2015 0.383 0.358 0.370\n",
      "2015-2020 0.576 0.854 0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.externals import joblib\n",
    "\n",
    "    # Load the lyrics from the json and tokenize\n",
    "    tokenized_lyrics, years = load_and_tokenize_data(\"songs/songs.json\")\n",
    "    \n",
    "    # split into test and training set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                tokenized_lyrics, years, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # create word embeddings\n",
    "    print(\"[Creating Word Embeddings]\")\n",
    "    w2v = gensim.models.Word2Vec(X_train, size=350, window=10, min_count=3, iter=30)\n",
    "    print(\"[Done: Saving Embeddings and printing out most similar words for 'money']\")\n",
    "    pprint(w2v.most_similar(['money']))\n",
    "    w2v.save('model_out/embeddings.model')\n",
    "    \n",
    "    # encode years to fit model\n",
    "    lb = LabelEncoder()\n",
    "    y = lb.fit_transform(y_train)\n",
    "    \n",
    "    # vector embeddings of songs\n",
    "    song_vec_train = [doc_vec(song) for song in X_train]\n",
    "    song_vec_test = [doc_vec(song) for song in X_test]\n",
    "    print(\"[Training model]\")\n",
    "\n",
    "    model = train_model(song_vec_train, y)\n",
    "    print(\"[Done: Now Saving Model]\")\n",
    "    joblib.dump(model, \"model_out/song2year.model\")    \n",
    "\n",
    "    test_and_print(song_vec_test, y_test, model, lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
