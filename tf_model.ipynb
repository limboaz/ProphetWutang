{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from pprint import pprint\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Isaac Duarte, Yinuo Zhang, Anthony Girard\n",
    "\n",
    "Attempt at Predicting release date of songs from their lyrics utlizing TensorFlow\n",
    "\n",
    "NOTE: This did not provide usable results unfortunately, however it does cover a number\n",
    "      of topics including RNNs, Word Embeddings, Logistic Regression, Tokenization.\n",
    "      \n",
    "SEE: song2year.ipynb for the actual model used to create our results\n",
    "\n",
    "Creating the model beigins as follows. Extracting and tokenizing lyrics and years\n",
    "from our data file. Creating a dictionary from the lyrics and encoding the lyrics\n",
    "using the indices of the words in the dictionary. \n",
    "\n",
    "Next a doc2vec model is produced using an RNN with batches produced via a skip gram \n",
    "model and gradient descent as the optimizer. This will ultimately produce vectors\n",
    "for songs by concatanating the sum of the vectors of the lyrics to the song, \n",
    "so hopefully similar songs are closer together, and thus songs of a similar year\n",
    "are more likely to be paired together.\n",
    "\n",
    "Afterwards a logistic (linear) regression model is used to fit the vectors to years.\n",
    "Such that a song's lyrics can be mapped to a vector and then to a year in order to predict\n",
    "the year that it came out. The loss function is cross entropy.\n",
    "\"\"\"\n",
    "\n",
    "space = re.compile(r'\\s')\n",
    "period = re.compile(r'(?<![A-Z])\\.|(?<!\\w)\\'(?!\\w)')\n",
    "punct = re.compile(r'[^\\'#@\\.\\w]')\n",
    "\n",
    "def tokenize(sent):\n",
    "    sent = space.split(sent)\n",
    "    to = []\n",
    "    tokens = []\n",
    "    for t in sent:\n",
    "        if t:\n",
    "            to += period.split(t)\n",
    "    for t in to:\n",
    "        if t:\n",
    "            tokens += punct.split(t)\n",
    "    return [a for a in tokens if a is not '']\n",
    "\n",
    "def get_lyrics_years(songs):\n",
    "    lyrics = []\n",
    "    years = []\n",
    "    \n",
    "    for song_id in list(songs.keys()):\n",
    "        lyrics.append(songs[song_id][\"lyrics\"].lower())\n",
    "        years.append(songs[song_id][\"year\"])\n",
    "        \n",
    "    return lyrics, years\n",
    "\n",
    "def dataset(lyrics, vocab_size):\n",
    "    # Words that were uncommon get noted as Out of bounds\n",
    "    count = [[\"OOB\", 0]]\n",
    "    count.extend(collections.\n",
    "                 Counter([word for lyric in lyrics for word in lyric]).\n",
    "                 most_common(vocab_size - 1))\n",
    "    word_to_index = {}\n",
    "    for word, _ in count:\n",
    "        word_to_index[word] = len(word_to_index)\n",
    "    encoded_lyrics = []\n",
    "    for song in lyrics:\n",
    "        encoded = []\n",
    "        for word in song:\n",
    "            index = word_to_index.get(word, 0)\n",
    "            if index == 0:\n",
    "                count[0][1] += 1\n",
    "            encoded.append(index)\n",
    "        encoded_lyrics.append(encoded)\n",
    "        index_to_word = dict(zip(word_to_index.values(), word_to_index.keys()))\n",
    "    return encoded_lyrics, count, word_to_index, index_to_word\n",
    "\n",
    "def generate_batch(lyrics, batch_size, window_size):\n",
    "    batch = []\n",
    "    labels = []\n",
    "    \n",
    "    while len(batch) < batch_size:\n",
    "        # select random song\n",
    "        r_song_index = int(np.random.choice(len(lyrics), size=1))\n",
    "        r_song = lyrics[r_song_index]\n",
    "        # generate window\n",
    "        window = [r_song[max(i - window_size, 0):(i + window_size + 1)] for i, _ in enumerate(r_song)]\n",
    "        \n",
    "        batch_labels = [(r_song[i:i + window_size], r_song[i + window_size]) for i in range(len(r_song) - window_size)]\n",
    "        if len(batch_labels) <= 2:\n",
    "            continue\n",
    "        # extract batch and label for this iteration\n",
    "        b, l = [list(x) for x in zip(*batch_labels)]\n",
    "        b = [x + [r_song_index] for x in b]\n",
    "        \n",
    "        batch.extend(b[:batch_size])\n",
    "        labels.extend(l[:batch_size])\n",
    "        \n",
    "    batch = batch[:batch_size]\n",
    "    labels = labels[:batch_size]\n",
    "    \n",
    "    batch = np.array(batch)\n",
    "    labels = np.transpose(np.array([labels]))\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "\n",
    "# Number of unique words to consider in our model\n",
    "vocabulary_size = 100000\n",
    "generations = 65000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# vector size\n",
    "embedding_size = 200\n",
    "song_embedding_size = 200\n",
    "concatenated_size = embedding_size + song_embedding_size\n",
    "\n",
    "# intervals to print out progress\n",
    "save_interval = 500\n",
    "print_loss_interval = 300\n",
    "\n",
    "# negative examples to sample\n",
    "num_sampled = 250\n",
    "\n",
    "window_size = 8\n",
    "\n",
    "data_folder = \"model_out\"\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tokenizing lyrics]\n",
      "[Done]\n",
      "[Encoding Lyrics]\n",
      "[Done]\n",
      "Number of songs: 17742\n"
     ]
    }
   ],
   "source": [
    "songs_filename = \"songs/songs.json\"\n",
    "songs_file = open(songs_filename, \"r+\")\n",
    "songs_dict = json.load(songs_file)\n",
    "\n",
    "\n",
    "lyrics, years = get_lyrics_years(songs_dict)\n",
    "\n",
    "tokenized_lyrics = []\n",
    "\n",
    "print(\"[Tokenizing lyrics]\")\n",
    "for l in lyrics:\n",
    "    tokenized_lyrics.append(tokenize(l))\n",
    "print(\"[Done]\")\n",
    "\n",
    "# encoded_lyrics is the original list of lyrics but with tokens\n",
    "# replaced with their corresponding dictionary index\n",
    "print(\"[Encoding Lyrics]\")\n",
    "encoded_lyrics, count, word_to_index, index_to_word = dataset(\n",
    "    tokenized_lyrics, vocabulary_size)\n",
    "print(\"[Done]\")\n",
    "\n",
    "del lyrics\n",
    "del tokenized_lyrics\n",
    "\n",
    "print(\"Number of songs:\", len(encoded_lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Creating Model]\n"
     ]
    }
   ],
   "source": [
    "print(\"[Creating Model]\")\n",
    "\n",
    "with tf.name_scope('inputs'):\n",
    "    x_inputs = tf.placeholder(tf.int32, shape=[None, window_size + 1])\n",
    "    y_target = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "\n",
    "with tf.name_scope('weights'):\n",
    "    nce_weights = tf.Variable(\n",
    "        tf.truncated_normal([vocabulary_size, concatenated_size],\n",
    "                           stddev=1.0 / np.sqrt(concatenated_size)))\n",
    "with tf.name_scope('biases'):\n",
    "    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    with tf.name_scope('embeddings'):\n",
    "        embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "        song_embeddings = tf.Variable(tf.random_uniform([len(encoded_lyrics), song_embedding_size], -1.0, 1.0))\n",
    "        embed = tf.zeros([batch_size, embedding_size])\n",
    "\n",
    "        # lookup word embeddings\n",
    "        for element in range(window_size):\n",
    "            embed += tf.nn.embedding_lookup(embeddings, x_inputs[:, element])\n",
    "\n",
    "        song_indices = tf.slice(x_inputs, [0, window_size], [batch_size, 1])\n",
    "        song_embed = tf.nn.embedding_lookup(song_embeddings, song_indices)\n",
    "\n",
    "        # concatenate embeddings\n",
    "        final_embed = tf.concat(axis=1, values=[embed, tf.squeeze(song_embed)])\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.nce_loss(\n",
    "            weights=nce_weights, biases=nce_biases,\n",
    "            inputs=final_embed, labels=y_target,\n",
    "            num_sampled=num_sampled, \n",
    "            num_classes=vocabulary_size))\n",
    "\n",
    "# SGD optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Create model saving operation\n",
    "saver = tf.train.Saver({\"embeddings\":embeddings, \"song_embeddings\": song_embeddings})\n",
    "\n",
    "# Initialize global varialbles\n",
    "init = tf.global_variables_initializer()\n",
    "print(\"[Done]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Starting Training]\n",
      "Loss at step 300 : 894.7554321289062\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 600 : 769.3016967773438\n",
      "Loss at step 900 : 838.2728271484375\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 1200 : 746.5286254882812\n",
      "Loss at step 1500 : 822.53271484375\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 1800 : 698.6054077148438\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 2100 : 648.1721801757812\n",
      "Loss at step 2400 : 656.0173950195312\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 2700 : 614.5010986328125\n",
      "Loss at step 3000 : 543.542724609375\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 3300 : 576.3624267578125\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 3600 : 468.9604187011719\n",
      "Loss at step 3900 : 500.3173522949219\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 4200 : 405.5291442871094\n",
      "Loss at step 4500 : 417.831298828125\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 4800 : 415.89495849609375\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 5100 : 309.1838073730469\n",
      "Loss at step 5400 : 307.41796875\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 5700 : 369.9382629394531\n",
      "Loss at step 6000 : 372.52581787109375\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 6300 : 358.0046691894531\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 6600 : 402.15948486328125\n",
      "Loss at step 6900 : 349.05694580078125\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 7200 : 324.2619934082031\n",
      "Loss at step 7500 : 226.8502655029297\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 7800 : 211.24618530273438\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 8100 : 149.49819946289062\n",
      "Loss at step 8400 : 201.53854370117188\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 8700 : 231.3423614501953\n",
      "Loss at step 9000 : 218.84715270996094\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 9300 : 180.33348083496094\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 9600 : 480.70025634765625\n",
      "Loss at step 9900 : 188.1788330078125\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 10200 : 191.9173583984375\n",
      "Loss at step 10500 : 238.0070343017578\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 10800 : 103.50360107421875\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 11100 : 164.6485137939453\n",
      "Loss at step 11400 : 169.90272521972656\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 11700 : 171.3509979248047\n",
      "Loss at step 12000 : 110.29349517822266\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 12300 : 201.01719665527344\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 12600 : 153.8363800048828\n",
      "Loss at step 12900 : 111.2946548461914\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 13200 : 76.5916519165039\n",
      "Loss at step 13500 : 119.7830810546875\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 13800 : 155.59664916992188\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 14100 : 97.04647827148438\n",
      "Loss at step 14400 : 134.1413116455078\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 14700 : 318.9073181152344\n",
      "Loss at step 15000 : 171.0585174560547\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 15300 : 66.26954650878906\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 15600 : 96.4621810913086\n",
      "Loss at step 15900 : 59.85159683227539\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 16200 : 114.78197479248047\n",
      "Loss at step 16500 : 150.4080352783203\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 16800 : 68.03392028808594\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 17100 : 80.56645965576172\n",
      "Loss at step 17400 : 52.60227966308594\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 17700 : 76.18167114257812\n",
      "Loss at step 18000 : 86.82231140136719\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 18300 : 55.78451919555664\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 18600 : 46.37813186645508\n",
      "Loss at step 18900 : 119.50764465332031\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 19200 : 42.27756881713867\n",
      "Loss at step 19500 : 67.80484008789062\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 19800 : 43.855682373046875\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 20100 : 44.85902786254883\n",
      "Loss at step 20400 : 74.18275451660156\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 20700 : 18.910858154296875\n",
      "Loss at step 21000 : 43.765296936035156\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 21300 : 39.50347137451172\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 21600 : 65.7573013305664\n",
      "Loss at step 21900 : 44.48316192626953\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 22200 : 49.14714050292969\n",
      "Loss at step 22500 : 35.669960021972656\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 22800 : 135.87001037597656\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 23100 : 34.6316032409668\n",
      "Loss at step 23400 : 108.36941528320312\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 23700 : 104.04122161865234\n",
      "Loss at step 24000 : 53.295555114746094\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 24300 : 27.25023651123047\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 24600 : 43.92141342163086\n",
      "Loss at step 24900 : 98.36727905273438\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 25200 : 22.132280349731445\n",
      "Loss at step 25500 : 54.50703048706055\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 25800 : 26.21962547302246\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 26100 : 47.625694274902344\n",
      "Loss at step 26400 : 232.7121124267578\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 26700 : 51.56270980834961\n",
      "Loss at step 27000 : 24.663013458251953\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 27300 : 47.92763900756836\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 27600 : 28.680021286010742\n",
      "Loss at step 27900 : 265.3913269042969\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 28200 : 46.986328125\n",
      "Loss at step 28500 : 51.36589813232422\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 28800 : 24.675771713256836\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 29100 : 29.764169692993164\n",
      "Loss at step 29400 : 41.91231918334961\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 29700 : 32.645572662353516\n",
      "Loss at step 30000 : 79.66415405273438\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 30300 : 37.114322662353516\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 30600 : 57.96173858642578\n",
      "Loss at step 30900 : 49.09840774536133\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 31200 : 29.873258590698242\n",
      "Loss at step 31500 : 30.175113677978516\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 31800 : 17.505922317504883\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 32100 : 33.1558837890625\n",
      "Loss at step 32400 : 37.25271987915039\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 32700 : 33.04969024658203\n",
      "Loss at step 33000 : 15.883641242980957\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 33300 : 202.465087890625\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 33600 : 21.698537826538086\n",
      "Loss at step 33900 : 378.2636413574219\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 34200 : 75.67296600341797\n",
      "Loss at step 34500 : 16.966970443725586\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 34800 : 30.204187393188477\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 35100 : 20.22604751586914\n",
      "Loss at step 35400 : 34.23610305786133\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 35700 : 17.620792388916016\n",
      "Loss at step 36000 : 16.359317779541016\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 36300 : 27.227312088012695\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 36600 : 83.9818115234375\n",
      "Loss at step 36900 : 103.4869155883789\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 37200 : 39.784263610839844\n",
      "Loss at step 37500 : 36.232086181640625\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 37800 : 21.627470016479492\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 38100 : 24.865127563476562\n",
      "Loss at step 38400 : 16.57744598388672\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 38700 : 24.42140769958496\n",
      "Loss at step 39000 : 41.483497619628906\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 39300 : 14.944501876831055\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 39600 : 24.403474807739258\n",
      "Loss at step 39900 : 58.1513557434082\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 40200 : 26.93543815612793\n",
      "Loss at step 40500 : 22.430118560791016\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 40800 : 24.596172332763672\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 41100 : 27.142303466796875\n",
      "Loss at step 41400 : 37.65311813354492\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 41700 : 32.88140106201172\n",
      "Loss at step 42000 : 34.30628204345703\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 42300 : 84.1115951538086\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 42600 : 17.07140350341797\n",
      "Loss at step 42900 : 17.395143508911133\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 43200 : 99.02738952636719\n",
      "Loss at step 43500 : 37.33631134033203\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 43800 : 33.108489990234375\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 44100 : 24.03017234802246\n",
      "Loss at step 44400 : 13.274309158325195\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 44700 : 17.288414001464844\n",
      "Loss at step 45000 : 16.283748626708984\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 45300 : 61.610870361328125\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 45600 : 24.298891067504883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 45900 : 17.900617599487305\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 46200 : 19.28911781311035\n",
      "Loss at step 46500 : 20.37373161315918\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 46800 : 24.469654083251953\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 47100 : 30.199838638305664\n",
      "Loss at step 47400 : 13.891159057617188\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 47700 : 23.10991859436035\n",
      "Loss at step 48000 : 26.634353637695312\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 48300 : 21.95051383972168\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 48600 : 23.241809844970703\n",
      "Loss at step 48900 : 13.427961349487305\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 49200 : 16.786293029785156\n",
      "Loss at step 49500 : 24.940914154052734\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 49800 : 39.73125457763672\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 50100 : 34.68321228027344\n",
      "Loss at step 50400 : 16.013858795166016\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 50700 : 10.739797592163086\n",
      "Loss at step 51000 : 11.931710243225098\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 51300 : 11.846426010131836\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 51600 : 23.404142379760742\n",
      "Loss at step 51900 : 24.00436782836914\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 52200 : 30.785594940185547\n",
      "Loss at step 52500 : 14.296835899353027\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 52800 : 12.341554641723633\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 53100 : 20.893033981323242\n",
      "Loss at step 53400 : 21.43939781188965\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 53700 : 14.340001106262207\n",
      "Loss at step 54000 : 76.50276184082031\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 54300 : 206.81544494628906\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 54600 : 18.02352523803711\n",
      "Loss at step 54900 : 21.216415405273438\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 55200 : 12.281317710876465\n",
      "Loss at step 55500 : 23.071043014526367\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 55800 : 32.575103759765625\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 56100 : 16.16888427734375\n",
      "Loss at step 56400 : 14.006072998046875\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 56700 : 16.96573257446289\n",
      "Loss at step 57000 : 12.831974983215332\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 57300 : 11.96611213684082\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 57600 : 12.807064056396484\n",
      "Loss at step 57900 : 33.615421295166016\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 58200 : 13.556219100952148\n",
      "Loss at step 58500 : 16.57868003845215\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 58800 : 11.792277336120605\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 59100 : 16.87462043762207\n",
      "Loss at step 59400 : 12.242995262145996\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 59700 : 19.233640670776367\n",
      "Loss at step 60000 : 12.1561918258667\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 60300 : 14.067963600158691\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 60600 : 26.552907943725586\n",
      "Loss at step 60900 : 18.57210922241211\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 61200 : 32.135162353515625\n",
      "Loss at step 61500 : 23.396764755249023\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 61800 : 16.509138107299805\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 62100 : 18.330768585205078\n",
      "Loss at step 62400 : 14.64450740814209\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 62700 : 67.28359985351562\n",
      "Loss at step 63000 : 67.4052963256836\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 63300 : 16.969738006591797\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 63600 : 19.92136573791504\n",
      "Loss at step 63900 : 19.046348571777344\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 64200 : 12.241294860839844\n",
      "Loss at step 64500 : 17.90412712097168\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "Loss at step 64800 : 12.170997619628906\n",
      "Model saved in file: C:\\Users\\isaac\\Desktop\\Dev_Stuff\\Projects\\ProphetWutang\\model_out\\doc2vec_song_embeddings.ckpt\n",
      "[Training doc2vec model Complete]\n"
     ]
    }
   ],
   "source": [
    "sess.run(init)\n",
    "print('[Starting Training]')\n",
    "\n",
    "loss_vec = []\n",
    "loss_x_vec = []\n",
    "\n",
    "for i in range(generations):\n",
    "    batch_inputs, batch_labels = generate_batch(encoded_lyrics, batch_size,\n",
    "                                               window_size)\n",
    "\n",
    "    feed_dict = {x_inputs: batch_inputs, y_target: batch_labels}\n",
    "    sess.run(optimizer, feed_dict=feed_dict)\n",
    "\n",
    "    # Return the loss\n",
    "    if (i + 1) % print_loss_interval == 0:\n",
    "        loss_val = sess.run(loss, feed_dict=feed_dict)\n",
    "        loss_vec.append(loss_val)\n",
    "        loss_x_vec.append(i + 1)\n",
    "        print('Loss at step {} : {}'.format(i + 1, loss_val))\n",
    "        \n",
    "    # Save dictionary + embeddings\n",
    "    if (i + 1) % save_interval == 0:\n",
    "        # Save vocabulary dictionary\n",
    "        with open(os.path.join(data_folder, 'songs_vocab.pkl'), 'wb') as f:\n",
    "            pickle.dump(word_to_index, f)\n",
    "\n",
    "        # Save embeddings\n",
    "        model_checkpoint_path = os.path.join('model_out/doc2vec_song_embeddings.ckpt')\n",
    "        save_path = saver.save(sess, model_checkpoint_path)\n",
    "        print('Model saved in file: {}'.format(save_path))\n",
    "print(\"[Training doc2vec model Complete]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.6397967   3.9534557   0.71651196 ... -0.74096954 -0.8555568\n",
      "   0.06410065]\n",
      " [-5.424506    4.6742377   1.4655683  ... -0.74096954 -0.8555568\n",
      "   0.06410065]\n",
      " [-4.279373    4.623521    0.33677125 ... -0.74096954 -0.8555568\n",
      "   0.06410065]\n",
      " ...\n",
      " [-4.3994093   6.5587897  -3.5923862  ... -0.74096954 -0.8555568\n",
      "   0.06410065]\n",
      " [-4.92293     6.477989   -3.197331   ... -0.74096954 -0.8555568\n",
      "   0.06410065]\n",
      " [-3.491235    6.3400855  -2.6646218  ... -0.74096954 -0.8555568\n",
      "   0.06410065]]\n"
     ]
    }
   ],
   "source": [
    "def lookup_embedding(elements, num_lookup, max_words):\n",
    "    documents = tf.constant(elements, dtype=tf.int32, shape=[num_lookup, max_words + 1])\n",
    "\n",
    "    word_embed = tf.zeros([num_lookup, embedding_size])\n",
    "\n",
    "    # lookup word embeddings\n",
    "    for element in range(max_words):\n",
    "        word_embed += tf.nn.embedding_lookup(embeddings, documents[:, element])\n",
    "\n",
    "    doc_indices = tf.slice(documents, [0, max_words], [num_lookup, 1])\n",
    "    doc_embed = tf.nn.embedding_lookup(song_embeddings, doc_indices, name=\"embedded_songs\")\n",
    "\n",
    "    # concatenate embeddings\n",
    "    return_embed = tf.concat(axis=1, values=[word_embed, tf.squeeze(doc_embed)], name=\"final_embedding\")\n",
    "    \n",
    "    return sess.run(return_embed)\n",
    "\n",
    "batch_inputs, _ = generate_batch(encoded_lyrics, batch_size, 50)\n",
    "test_embeddings = lookup_embedding(batch_inputs, batch_size, 50)\n",
    "print(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Start logistic model-------------------------\n",
    "max_words = 50\n",
    "logistic_batch_size = 500\n",
    "\n",
    "encoded_lyrics = np.array(encoded_lyrics)\n",
    "years = np.array(years)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    encoded_lyrics, years, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train = np.array([x[0:max_words] for x in [y + [0] * max_words for y in X_train]])\n",
    "X_test = np.array([x[0:max_words] for x in [y + [0] * max_words for y in X_test]])\n",
    "\n",
    "with tf.name_scope('inputs'):\n",
    "    X = tf.placeholder(tf.float32, shape=[logistic_batch_size, concatenated_size], name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=[logistic_batch_size, 1], name=\"y\")\n",
    "        \n",
    "with tf.name_scope('weights'):\n",
    "    betas = tf.Variable(tf.random_uniform([concatenated_size, 1], -1, 1))\n",
    "\n",
    "# Actual Prediction\n",
    "y_pred = tf.nn.softmax(tf.matmul(X, betas))\n",
    "\n",
    "with tf.name_scope('cost'):\n",
    "    penalized_cost = tf.reduce_sum(tf.square(y - y_pred)) + 1.0 * tf.reduce_sum(tf.square(betas))\n",
    "    #tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_pred)\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    log_optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "    log_training = log_optimizer.minimize(penalized_cost)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Intitialize Variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Starting Logistic Doc2Vec Model Training]\n",
      "Step: 50 First 5 Betas [[-2.2154118e-06]\n",
      " [-1.3136296e-05]\n",
      " [-1.2596138e-05]\n",
      " [-1.2523004e-05]\n",
      " [ 6.3387114e-07]]\n",
      "Step: 50 Penalized Cost 2021646700.0\n",
      "Step: 100 First 5 Betas [[-3.1619412e-11]\n",
      " [-1.8748747e-10]\n",
      " [-1.7977811e-10]\n",
      " [-1.7873433e-10]\n",
      " [ 9.0469125e-12]]\n",
      "Step: 100 Penalized Cost 2021966300.0\n",
      "Step: 150 First 5 Betas [[-4.5128740e-16]\n",
      " [-2.6759105e-15]\n",
      " [-2.5658792e-15]\n",
      " [-2.5509816e-15]\n",
      " [ 1.2912181e-16]]\n",
      "Step: 150 Penalized Cost 2020895400.0\n"
     ]
    }
   ],
   "source": [
    "# Start Logistic Regression\n",
    "print('[Starting Logistic Doc2Vec Model Training]')\n",
    "for i in range(10000):\n",
    "    rand_index = np.random.choice(X_train.shape[0], size=logistic_batch_size)\n",
    "    rand_x = X_train[rand_index]\n",
    "    # Append song index at the end of lyrics data\n",
    "    rand_x_doc_indices = np.sort(rand_index)\n",
    "    rand_x = np.hstack((rand_x, np.transpose([rand_x_doc_indices])))\n",
    "    rand_y = np.transpose([y_train[rand_index]])\n",
    "    \n",
    "    x_embeddings = lookup_embedding(rand_x, logistic_batch_size, max_words)\n",
    "    \n",
    "    feed_dict = {X: x_embeddings, y: rand_y}\n",
    "    sess.run(log_training, feed_dict=feed_dict)\n",
    "\n",
    "    # Only record loss and accuracy every 100 generations\n",
    "    if (i + 1) % 50 == 0:\n",
    "        #print(x_embeddings)\n",
    "        print(\"Step:\", i + 1, \"First 5 Betas\", sess.run(betas, feed_dict=feed_dict)[0:5])\n",
    "        print(\"Step:\", i + 1, \"Penalized Cost\", sess.run(penalized_cost, feed_dict=feed_dict))\n",
    "        \n",
    "    if (i + 1) % 500 == 0:\n",
    "        model_checkpoint_path = os.path.join('model_out/doc2vec_log_reg_model.ckpt')\n",
    "        save_path = saver.save(sess, model_checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
